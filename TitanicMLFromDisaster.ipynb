{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# reference for this projects: https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n# learning basic Machine Learning processes in Python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt # plotting framework\nimport seaborn as sns # for data visualization\n%matplotlib inline \n\n\n# turning CSV -> DataFrame\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ntrain_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing data to find patterns in the data\n#seaborn references: https://seaborn.pydata.org/introduction.html\n\n#groups of people who were more likely to survive: women, children, and upperclass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Transformation \n-group people into age groups\n\n-drop useless features (ticket, name, numbers in cabin)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def simplify_ages(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n    categories = pd.cut(df.Age, bins, labels=group_names)\n    df.Age = categories\n    return df\n\ndef simplify_cabins(df):\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    return df\n\ndef simplify_fares(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n    categories = pd.cut(df.Fare, bins, labels=group_names)\n    df.Fare = categories\n    return df\n\ndef format_name(df):\n    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n    return df    \n    \ndef drop_features(df):\n    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n\ndef transform_features(df):\n    df = simplify_ages(df)\n    df = simplify_cabins(df)\n    df = simplify_fares(df)\n    df = format_name(df)\n    df = drop_features(df)\n    return df\n\ntrain_data = transform_features(train_data)\ntest_data = transform_features(test_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=train_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Cabin\", y=\"Survived\", hue=\"Sex\", data=train_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Fare\", y=\"Survived\", hue=\"Sex\", data=train_data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalize labels\n-LabelEncoder in Scikit-learn converts each unique string value into a number-> makes data more flexible "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\ndef encode_features(df_train, df_test):\n    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n    \ntrain_data, test_data = encode_features(train_data, test_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting up the training data\nX_all: feaures minus value we want to predict\n\ny_all: value we want to predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_all = train_data.drop(['Survived', 'PassengerId'], axis=1)\ny_all = train_data['Survived']\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit and tune an algorithm\n\nusing RandomForestClassifer (try to test using SVM in future)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [4, 6, 9], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(X_test)\nprint(accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validating algorithm with KFold\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nrf = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(rf, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting the actual test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = test_data['PassengerId']\npredictions = clf.predict(test_data.drop('PassengerId', axis=1))\n\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('titanic-predictions.csv', index = False)\noutput.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}